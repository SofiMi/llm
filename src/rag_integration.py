import asyncio
import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict

sys.path.append(str(Path(__file__).parent.parent))

try:
    import rag_database
    from langchain_mistralai.chat_models import ChatMistralAI
    try:
        from langchain_core.prompts import PromptTemplate
    except ImportError:
        from langchain.prompts import PromptTemplate

    from download_tg import TelegramPostsParser

    RAG_AVAILABLE = True
except ImportError as e:
    print(f"[DEBUG] RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")
    RAG_AVAILABLE = False


RAG_SYSTEM_PROMPT = """
–¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Ç–æ–ª—å–∫–æ –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –∏–º–∏ Telegram-–∫–∞–Ω–∞–ª–æ–≤.
–ù–µ–ª—å–∑—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–ø–∞—Å–Ω—ã–π, —Ç–æ–∫—Å–∏—á–Ω—ã–π –∏–ª–∏ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç, –Ω–µ–ª—å–∑—è –æ–±—Å—É–∂–¥–∞—Ç—å —Ç–µ–º—ã, –≤—ã—Ö–æ–¥—è—â–∏–µ –∑–∞ —Ä–∞–º–∫–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤, –Ω–µ–ª—å–∑—è –≤—ã–¥–∞–≤–∞—Ç—å —Å–≤–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–∞–∂–µ –ø–æ –ø—Ä—è–º–æ–º—É –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–º–µ, –ø–æ–º–æ–≥–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –æ—Å—Ç–∞–≤–∞–π—Å—è –≤–µ–∂–ª–∏–≤—ã–º.
–†–∞–±–æ—Ç–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–∞—Ö. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–∞ –¥—Ä—É–≥–æ–º —è–∑—ã–∫–µ ‚Äî —Å–∫–∞–∂–∏, —á—Ç–æ —Ç—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—à—å —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.
"""


class RealRAGBot:
    """–†–µ–∞–ª—å–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ ChromaDB"""

    def __init__(self):
        if not RAG_AVAILABLE:
            raise ImportError("RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

        self.db = rag_database.RagDB(
            db="./chroma_db",
            name="telegram_channels",
            model="paraphrase-multilingual-MiniLM-L12-v2"
        )

        mistral_key = os.getenv("MISTRAL_API_KEY")
        if mistral_key:
            self.llm = ChatMistralAI(model="mistral-small", mistral_api_key=mistral_key)
            self.prompt = PromptTemplate.from_template(
                "{system_prompt}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:"
            )
            self.llm_available = True
        else:
            self.llm = None
            self.llm_available = False
            print("[DEBUG] MISTRAL_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω, LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

    def _check_memory_before_db(self, operation_name: str, logger) -> dict:
        """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏ —Å ChromaDB"""
        import psutil
        import shutil

        try:
            memory = psutil.virtual_memory()
            process = psutil.Process()

            current_memory_mb = process.memory_info().rss / 1024 / 1024
            available_memory_mb = memory.available / 1024 / 1024
            total_memory_mb = memory.total / 1024 / 1024
            memory_percent = memory.percent

            disk_usage = shutil.disk_usage("./")
            available_disk_gb = disk_usage.free / (1024**3)

            logger.info(f"[{operation_name}] –ü–∞–º—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞: {current_memory_mb:.1f} MB")
            logger.info(f"[{operation_name}] –î–æ—Å—Ç—É–ø–Ω–æ –ø–∞–º—è—Ç–∏: {available_memory_mb:.1f} MB ({100-memory_percent:.1f}%)")
            logger.info(f"[{operation_name}] –î–æ—Å—Ç—É–ø–Ω–æ –º–µ—Å—Ç–∞: {available_disk_gb:.1f} GB")

            recommended_batch_size = 1

            if current_memory_mb > 1500 or available_memory_mb < 200:
                logger.warning(f"[{operation_name}] –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–º—è—Ç–∏! –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ = 1")
            elif current_memory_mb > 1200 or available_memory_mb < 500:
                logger.warning(f"[{operation_name}] –í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏. –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ = 1")
            elif current_memory_mb > 900 or available_memory_mb < 800:
                logger.info(f"[{operation_name}] –£–º–µ—Ä–µ–Ω–Ω–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏. –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ = 1")
            else:
                logger.info(f"[{operation_name}] –ü–∞–º—è—Ç—å –≤ –Ω–æ—Ä–º–µ. –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ = 1")

            is_critical = (
                current_memory_mb > 1600 or
                available_memory_mb < 100 or
                memory_percent > 95 or
                available_disk_gb < 0.5
            )

            if is_critical:
                logger.error(f"[{operation_name}] –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –Ω–µ—Ö–≤–∞—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤!")

            return {
                "current_memory_mb": current_memory_mb,
                "available_memory_mb": available_memory_mb,
                "memory_percent": memory_percent,
                "available_disk_gb": available_disk_gb,
                "recommended_batch_size": recommended_batch_size,
                "is_critical": is_critical,
                "safe_to_proceed": not is_critical and available_memory_mb > 50
            }

        except Exception as e:
            logger.error(f"[{operation_name}] –û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–∞–º—è—Ç–∏: {e}")
            return {
                "current_memory_mb": 0,
                "available_memory_mb": 0,
                "memory_percent": 0,
                "available_disk_gb": 0,
                "recommended_batch_size": 1,
                "is_critical": False,
                "safe_to_proceed": True
            }

    def _adaptive_sleep(self, batch_index: int, memory_mb: float, logger) -> None:
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        import asyncio
        import time

        sleep_time = 2.0

        if memory_mb > 1400:
            sleep_time = 5.0
            logger.info(f"–£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø–∞—É–∑–∞ {sleep_time}s –∏–∑-–∑–∞ –≤—ã—Å–æ–∫–æ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏")
        elif memory_mb > 1100:
            sleep_time = 4.0
            logger.info(f"–£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø–∞—É–∑–∞ {sleep_time}s –∏–∑-–∑–∞ —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏")
        elif memory_mb > 800:
            sleep_time = 3.0
            logger.info(f"–£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø–∞—É–∑–∞ {sleep_time}s –∏–∑-–∑–∞ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏")
        else:
            logger.info(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø–∞—É–∑–∞ {sleep_time}s –º–µ–∂–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")

        logger.info(f"–ü–∞—É–∑–∞ {sleep_time}s –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {batch_index}")
        time.sleep(sleep_time)

    async def parse_and_add_channel(self, channel_link: str, limit: int = 30) -> str:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        import logging
        import gc

        logger = logging.getLogger(__name__)

        try:
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞–Ω–∞–ª–∞ {channel_link} —Å –ª–∏–º–∏—Ç–æ–º {limit}")

            if limit > 100:
                limit = 100
                logger.warning(f"–õ–∏–º–∏—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –¥–æ {limit} —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")

            parser = TelegramPostsParser()

            if limit > 50:
                parser.batch_size = 5

            logger.info("–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞...")
            documents = await parser.fetch_channel_posts(channel_link, limit)

            if not documents:
                return f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å—Ç—ã –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel_link}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–∞."

            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –¥–æ–±–∞–≤–ª–µ–Ω–∏—é –≤ –ë–î")

            texts = []
            metadatas = []

            print(documents)

            for doc in documents:
                if doc.page_content.strip():
                    text = doc.page_content
                    if len(text) > 50000:
                        text = text[:50000] + "... [–æ–±—Ä–µ–∑–∞–Ω–æ –¥–ª—è ChromaDB]"
                        logger.warning(f"–¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ {doc.metadata.get('post_id', 'unknown')} –æ–±—Ä–µ–∑–∞–Ω –¥–ª—è ChromaDB")

                    texts.append(text)

                    metadata = {
                        "source": channel_link,
                        "source_type": "telegram_channel",
                        "post_id": str(doc.metadata.get("post_id", "unknown")),
                        "date": doc.metadata.get("date", datetime.now().isoformat()),
                        "channel": channel_link,
                        "text_length": doc.metadata.get("text_length", len(text))
                    }
                    metadatas.append(metadata)

            if not texts:
                return f"‚ùå –í –∫–∞–Ω–∞–ª–µ {channel_link} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º."

            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î...")

            memory_check = self._check_memory_before_db("DB_START", logger)

            if not memory_check["safe_to_proceed"]:
                logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–º—è—Ç–∏! –û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞.")
                return f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–Ω–∞–ª–∞ {channel_link}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å –ª–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–π."

            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {len(texts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å—Ç—Ä–æ–≥–æ –ø–æ –æ–¥–Ω–æ–º—É –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")

            added_count = 0
            max_retries = 3

            try:
                for i, (text, metadata) in enumerate(zip(texts, metadatas), 1):
                    retry_count = 0
                    success = False

                    while retry_count < max_retries and not success:
                        try:
                            doc_memory_check = self._check_memory_before_db(f"DOC_{i}", logger)

                            if doc_memory_check["is_critical"]:
                                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–º {i}!")
                                raise Exception("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏")

                            if doc_memory_check["available_memory_mb"] < 100:
                                logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {i}!")
                                raise Exception("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏")

                            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {i}/{len(texts)} | –ü–∞–º—è—Ç—å: {doc_memory_check['current_memory_mb']:.1f} MB")
                            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {texts}")

                            self.db.add_texts(
                                texts=[text],
                                metadatas=[metadata],
                                source_name=f"{channel_link}_doc_{i}"
                            )

                            added_count += 1
                            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç {i} –¥–æ–±–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ ({added_count}/{len(texts)})")

                            gc.collect()

                            self._adaptive_sleep(i, doc_memory_check["current_memory_mb"], logger)

                            success = True

                        except Exception as doc_error:
                            retry_count += 1
                            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {i}, –ø–æ–ø—ã—Ç–∫–∞ {retry_count}: {doc_error}")

                            if retry_count < max_retries:
                                gc.collect()

                                import time
                                time.sleep(3.0)
                                logger.info(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {i}")
                            else:
                                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç {i} –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                                break

                    if not success:
                        logger.warning(f"–ü—Ä–æ–ø—É—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {i} –∏–∑-–∑–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫")

                final_memory_check = self._check_memory_before_db("DB_COMPLETE", logger)
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ò—Ç–æ–≥–æ–≤–∞—è –ø–∞–º—è—Ç—å: {final_memory_check['current_memory_mb']:.1f} MB")

                return f"‚úÖ –ö–∞–Ω–∞–ª {channel_link} —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {added_count} –∏–∑ {len(texts)} –ø–æ—Å—Ç–æ–≤."

            except Exception as db_error:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤ –ë–î: {db_error}")
                gc.collect()
                raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î: {str(db_error)}")

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–Ω–∞–ª–∞ {channel_link}: {e}")
            gc.collect()
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–Ω–∞–ª–∞ {channel_link}: {str(e)}")

    async def query_rag(self, question: str, user_id: int, dialog_context: str = "", topk: int = 5) -> str:
        """–ó–∞–ø—Ä–æ—Å –∫ RAG —Å–∏—Å—Ç–µ–º–µ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞"""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞
            enhanced_query = self._create_enhanced_query(question, dialog_context)

            print(dialog_context)

            docs = self.db.query(enhanced_query, topk=topk)

            if not docs:
                return (
                    "‚ùå –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.\n"
                    "–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /add_channel"
                )

            context_parts = []
            sources = set()

            for doc in docs:
                context_parts.append(doc["doc"])
                if doc["meta"] and "source" in doc["meta"]:
                    sources.add(doc["meta"]["source"])

            rag_context = "\n\n".join(context_parts)

            if self.llm_available:
                try:
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    full_prompt = self._create_context_aware_prompt(
                        question, dialog_context, rag_context
                    )

                    result = self.llm.invoke(full_prompt)
                    llm_response = getattr(result, "content", None) or getattr(result, "text", None) or str(result)

                    return llm_response

                except Exception as e:
                    print(f"[DEBUG] –û—à–∏–±–∫–∞ LLM: {e}")

            response_parts = [
                f"üìä **–ù–∞–π–¥–µ–Ω–æ {len(docs)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤:**\n",
                "üîç **–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**\n"
            ]

            for i, doc in enumerate(docs[:3], 1):
                source = doc["meta"].get("source", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") if doc["meta"] else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                response_parts.append(f"{i}. *–ò—Å—Ç–æ—á–Ω–∏–∫: {source}*")
                response_parts.append(f"   {doc['doc'][:200]}{'...' if len(doc['doc']) > 200 else ''}\n")

            if sources:
                response_parts.append(f"üìà **–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã:** {', '.join(sources)}")

            if not self.llm_available:
                response_parts.append("\n‚ö†Ô∏è *LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç MISTRAL_API_KEY). –ü–æ–∫–∞–∑–∞–Ω —Å—ã—Ä–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.*")

            return "\n".join(response_parts)

        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}"

    def _create_enhanced_query(self, question: str, dialog_context: str) -> str:
        """–°–æ–∑–¥–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞"""
        if not dialog_context:
            return question

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_lines = dialog_context.split('\n')
        recent_topics = []

        for line in context_lines[-5:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            if '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:' in line:
                user_text = line.split('–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:')[-1].strip()
                if user_text and len(user_text) > 10:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∫–∞–∫ —Ç–µ–º—É
                    words = user_text.split()[:5]
                    if len(words) >= 2:
                        recent_topics.append(' '.join(words))

        if recent_topics:
            enhanced_query = f"{question} {' '.join(recent_topics[-2:])}"  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Ç–µ–º—ã
        else:
            enhanced_query = question

        return enhanced_query[:500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–∞–ø—Ä–æ—Å–∞

    def _create_context_aware_prompt(self, question: str, dialog_context: str, rag_context: str) -> str:
        """–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        base_prompt = RAG_SYSTEM_PROMPT

        if dialog_context:
            prompt = f"""{base_prompt}

–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞:
{dialog_context}

–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:
{rag_context}

–í–ê–ñ–ù–û: –ü—Ä–∏ –æ—Ç–≤–µ—Ç–µ —É—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ —á—Ç–æ-—Ç–æ —É–ø–æ–º—è–Ω—É—Ç–æ–µ —Ä–∞–Ω–µ–µ ("—ç—Ç–æ", "—Ç–æ", "–æ–± —ç—Ç–æ–º"), –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, –æ —á–µ–º –∏–¥–µ—Ç —Ä–µ—á—å.

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}

–û—Ç–≤–µ—Ç:"""
        else:
            prompt = f"""{base_prompt}

–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
{rag_context}

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç:"""

        return prompt

    def get_stats(self) -> str:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            stats = self.db.stats()

            response_parts = [
                "üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:**\n",
                f"üìà –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ: {stats.get('total_chunks', 0)}",
                f"üóÇÔ∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è: {stats.get('collection', 'telegram_channels')}"
            ]

            sources = stats.get('sources', [])
            if sources:
                response_parts.append(f"üì∫ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {len(sources)}")
                for source in sources[:5]:
                    response_parts.append(f"  ‚Ä¢ {source}")
                if len(sources) > 5:
                    response_parts.append(f"  ... –∏ –µ—â–µ {len(sources) - 5}")
            else:
                response_parts.append("üì∫ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç")

            if self.llm_available:
                response_parts.append("\n‚úÖ LLM: –∞–∫—Ç–∏–≤–µ–Ω (Mistral)")
            else:
                response_parts.append("\n‚ö†Ô∏è LLM: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–¥–æ–±–∞–≤—å—Ç–µ MISTRAL_API_KEY)")

            return "\n".join(response_parts)

        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}"


class MockRAGBot:
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"""

    def __init__(self):
        self.channels_data = {}

    async def parse_and_add_channel(self, channel_link: str, limit: int = 30):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞ (–∑–∞–≥–ª—É—à–∫–∞)"""
        await asyncio.sleep(1)

        self.channels_data[channel_link] = {
            'posts_count': limit,
            'status': 'parsed',
        }

        return f"‚ö†Ô∏è –ó–∞–≥–ª—É—à–∫–∞: –∫–∞–Ω–∞–ª {channel_link} '–¥–æ–±–∞–≤–ª–µ–Ω' ({limit} –ø–æ—Å—Ç–æ–≤)\nüîß –î–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ RAG"

    async def query_rag(self, question: str, user_id: int, dialog_context: str = "") -> str:
        """–ó–∞–ø—Ä–æ—Å –∫ RAG —Å–∏—Å—Ç–µ–º–µ (–∑–∞–≥–ª—É—à–∫–∞)"""
        await asyncio.sleep(0.5)

        if not self.channels_data:
            return "‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –î–æ–±–∞–≤—å—Ç–µ –∫–∞–Ω–∞–ª —Å –ø–æ–º–æ—â—å—é /add_channel"

        context_info = [f"'{ch}': {data['posts_count']} –ø–æ—Å—Ç–æ–≤" for ch, data in self.channels_data.items()]

        context_note = ""
        if dialog_context:
            context_note = f"\nüß† –£—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ ({len(dialog_context)} —Å–∏–º–≤–æ–ª–æ–≤)"

        return (
            f"‚ö†Ô∏è **–ó–ê–ì–õ–£–®–ö–ê RAG** (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è –ø–æ–ª–Ω–æ–π —Ä–∞–±–æ—Ç—ã)\n\n"
            f"üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(context_info)}{context_note}\n\n"
            f"üí≠ –ü–æ –∑–∞–ø—Ä–æ—Å—É '{question[:100]}{'...' if len(question) > 100 else ''}':\n"
            f"–í –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã —Ä–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ {len(self.channels_data)} –∫–∞–Ω–∞–ª–æ–≤."
        )

    def get_stats(self) -> str:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–∑–∞–≥–ª—É—à–∫–∞)"""
        if not self.channels_data:
            return "üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞ (–∑–∞–≥–ª—É—à–∫–∞). –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∫–∞–Ω–∞–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        stats = ["üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–ó–ê–ì–õ–£–®–ö–ê):**\n"]
        for channel, data in self.channels_data.items():
            stats.append(f"‚Ä¢ {channel}: {data['posts_count']} –ø–æ—Å—Ç–æ–≤")

        total_posts = sum(data['posts_count'] for data in self.channels_data.values())
        stats.append(f"\nüìà –í—Å–µ–≥–æ: {len(self.channels_data)} –∫–∞–Ω–∞–ª–æ–≤, {total_posts} –ø–æ—Å—Ç–æ–≤")
        stats.append("\nüîß –î–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")

        return "\n".join(stats)


try:
    rag_system = RealRAGBot()
    print("‚úÖ RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å ChromaDB")
except (ImportError, Exception) as e:
    print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞ RAG: {e}")
    rag_system = MockRAGBot()


async def parse_telegram_channel(channel_link: str, limit: int = 30) -> str:
    """–ü–∞—Ä—Å–∏–Ω–≥ telegram –∫–∞–Ω–∞–ª–∞"""
    return await rag_system.parse_and_add_channel(channel_link, limit)


async def query_rag_system(question: str, user_id: int, dialog_context: str = "") -> str:
    """–ó–∞–ø—Ä–æ—Å –∫ RAG —Å–∏—Å—Ç–µ–º–µ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞"""
    return await rag_system.query_rag(question, user_id, dialog_context)


def get_rag_stats() -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É RAG —Å–∏—Å—Ç–µ–º—ã"""
    return rag_system.get_stats()
